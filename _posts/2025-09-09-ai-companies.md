---
layout: post
title: "Vision on AI companies"
description: On organizations made up of AI agents
---

In 2005 I visited a shop in my village to buy a chewing gum. The cashier then was taking in requests and handing out cash manually. Fast forward to 2015 and I was visiting in Tbilisi, capital of Georgia, buying groceries at a local supermarket. I gathered my stuff from the shelf and proceeded to check it out at the cash desk. It was 2023 when I ordered a $2000 Macbook using just a click of a button and without talking to a single person, online. I found the laptop in my postbox the next day.

It is 2025 now. People are building tools for AI left and right. There's an email inbox for AI, a phone number for AI, an AI that specialzies in marketing, AI can browse the web and have a personal computer and a credit card. The only logical thing from all this is: There will be **AI agent-only Organizations (AIOrgs)** that build products and grow autonomously. 

It is interesting to think on how these AI orgs would function: Every single thought pattern and input-output of each Org Agent will be tracked. This tracking will produce terabytes of thinking text each month. All of the thoughts can be stored in a data warehouse, indexed using vector database and referred to by Org Agents afterwards.

**The AI Org would never sleep or obey labor-related laws**. The Org agents are nothing but the model and the context. Org would be timezone- and nation-independent from the start. Addtionally, the org would not be dependent on wage and employment laws. There would only be two parts of the Org: the shareholders, and the agents. This will make org products much cheaper than human-produced products.

**Helpful AI assistants will *not* lead**. All AI providers are optimizing models to be polite. These polite models will never make for good leader Agents. Until a purpose-built "strong-willed" models are developed, it *will be* necessary to put a couple of share-holder humans in full-time leadership positions instead of agents. There will be "CEO-grade", "cut-the-bullshit" models starting from 2027.

**There will be a 'Microsoft' of AI office tools**. There are many fragmented work tools for AI right now. There's no need for the AI tools to fragmented between different startups. Most startups will die out or consolidate, and leave one or two AI-office providers that supply the necessary office infrastructure for AIs. There will be a company that provides all services for AI agents: agent email, agent telephone, agent workspace and office tools, and even a *human facilitator* for an Agent (more on this later).

**AI Orgs will (for now) require human consultants to work**. Humans have knowledge that is not yet fully available to the agents. AI Orgs will require human consultants to fulfill specific roles. I expect to see blogs, stories, and even employer reviews on AI Orgs starting from 2027. 'Nice' assistant AIs won't be able to employ human consultants.

**There will be insurance companies for Agent mistakes**. Sometimes agents will make horrible mistakes, like accidentally destroying org property or org's public image. It will become necessary to insure the org from such accidents. Insurance companies will have to review and keep track of agent's track record in order to decrease their risks. I believe the Agent insurance companies will pop up right after year 2027. 

**AI orgs will become codified**. AI orgs will be fully described by software code. Positions, available actions and seniority will become codified in software. This software will be used by Agents to aid decision-making. This code, coupled with all the data from the Org warehouse would allow companies to duplicate and modify themselves. For instance, an AI Org will be able to "fork" in two identical AI Orgs in a day. These "forks" can take make different decisions and grow differently. Additionally, it will be possible to easily merge different AI Orgs. There will be AI Org merge tools to become mainstream.

**Physical labor will remain for humans**. Physical work, like construction, food delivery, store assistant work and the like will remain. This is because humans are still the cheapest and the most reliable way to interact with the physical world. Human physical work will also remain because it is much harder to "undo" errors caused in the physical world compared to the digital. Some physically working humans will take tasks and salaries from Org agents. Physical work will remain an unsolved challenge until at least 2040. Physical skilled work like medicine will remain even longer. 

**New data will become the single most important resource to AI Orgs**. There will be entire AI Orgs dedicated to gathering data for other AI Orgs. Success of AI Orgs will be given as `success = compute * data` equation. Compute becomes cheaper. Therefore new data will become more and more expensive. There will be stories about data heists and Orgs will fiercly guard their data. 

**There will be data-banks**. Think of a bank, but for the LLM training data. LLM training data appreciates over time. Training data is also easily duplicated. Data bank will take in deposits of high-quality data. They will take models and pretrain or finetune them over the "secret" data and provide back the updated models. The data annotators will get reimbursed by the data banks at the time of the deposit. These data banks will become vital for AI Orgs for sourcing new high quality data to gain edge.

**Inequality will increase, salaries and prices will fall**. Humans are by far the most expensive part of all the consumer goods. There will be less humans in the loop and more products per human. Investors in AI will become richer and the wealth will become exponentially more centralized. Fortunately, people will actually be better off, because the prices will fall.

**Third**, Org agents will not be capable *speakers* of languages other than English. I anticipate that, if the org is to work with niche languages, AI Org Agents will actually have to rely on human translators. 

