---
layout: page
title: ArxivGPT-2 - scientific writing assistant
description: We have Codex for coding assistance. Why not also use transformers for assiting with scientific writing? This is where this project comes in.
img: https://i.imgur.com/8FJwqFy.gif
# redirect: https://tornikeo.github.io/blogs-for-the-blog-god/
importance: 2
category: work
---



Written by: [@tornikeo](https://github.com/tornikeo) and [@copilot](https://copilot.github.com/)

[Attentional models](https://arxiv.org/abs/1706.03762) have seen a huge growth in popularity. At first, within NLP and later in other domains, such as vision, reinforcement learning and speech.Not to mention that they are capable of quickly adapting to [any *computable* task out there](https://arxiv.org/abs/2103.05247). So, in this blogpost, I will walk through a sample application that can help *you* become the prolific researcher you always dreamed to be.


Shown below is a ready-to-use writer. Here are some basic instructions if you have never used an editor:
- You can write, copy, remove or edit the text below.
- To get the suggested next words, press <kbd>tab</kbd>
- To select the suggestion, use <kbd>↑</kbd> <kbd>↓</kbd> arrows
- Press <kbd>enter</kbd> to paste the suggestion
- To ignore suggestion, press <kbd>esc</kbd>

*tip: click anywhere within the box and press `tab` to get started*

<iframe width="100%" height="315" src="https://tornikeo.github.io/blogs-for-the-blog-god/" frameborder="0" allowfullscreen></iframe>