<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Tornike  Onoprishvili | 2D Material Detection for Robotic Control</title>
    <meta name="author" content="Tornike  Onoprishvili" />
    <meta name="description" content="Automate 2D material detection for robotics." />
    <meta name="keywords" content="tornikeo, tornike, onoprishvili, ai, llm, portfolio, machine learning, researcher, scientist" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22https://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://tornikeo.com/projects/atomic_arch/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <meta name="referrer" content="no-referrer">
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://tornikeo.com/"><span class="font-weight-bold">Tornike</span>   Onoprishvili</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>

              <!-- Other pages -->
                <li class="nav-item ">
                  <a class="nav-link" href="/projects/">projects</a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/publications/">publications</a>
                </li>
                
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Resume: Direct link to PDF asset -->
              <li class="nav-item">
                <a class="nav-link" href="https://raw.githubusercontent.com/tornikeo/cdn/master/assets/resume/tornikeo.pdf" target="_blank" rel="noopener noreferrer">resume
                </a>
              </li>

              <!-- Toggle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
<div class="post">

  <header class="post-header">
    <h1 class="post-title">2D Material Detection for Robotic Control</h1>
    <p class="post-description">Automate 2D material detection for robotics.</p>
  </header>

  <article>
    <h1 id="the-problem">The problem</h1>

<p>In this blog, I’ll describe how I built a classical computer vision tool for tracking microscopic 2-dimensional flakes, using virtually zero annotated data. The code is <a href="https://github.com/tornikeo/atomic-architects" target="_blank" rel="noopener noreferrer">available online</a>. Here’s what I mean by microscopic flakes:</p>

<figure>
  <div class="container text-center">
  <video height="" class="" width="70%" autoplay="" loop="" muted="">
    <!-- <img  src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/aa-raw-compressed.mp4"    /> -->
    <source src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/aa-raw-compressed.mp4" type="video/mp4"></source>

  </video>
</div>
<figcaption class="caption"><p>One example of an input video feed, straight from the microscope.</p>
</figcaption></figure>

<p>This video shows a transfer of a single microscopic flake to a substrate (fancy name for a floor). If you look at this video from the side, you’d see something like below:</p>
<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-1-480.webp" />
    <source media="(max-width: 800px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-1-800.webp" />
    <source media="(max-width: 1400px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-1-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-1.png" data-zoomable="">
  </picture>
</figure>

<p>The camera starts by looking through a plastic sheet that has a flake attached to it. The sheet is transparent and out of focus, so it is very blurry initially. The plastic sheet is then lowered to the substrate and it then becomes visible. This step looks like this:</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-2-480.webp" />
    <source media="(max-width: 800px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-2-800.webp" />
    <source media="(max-width: 1400px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-2-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-2.png" data-zoomable="">
  </picture>
</figure>

<p>At this point, the flake sticks to the substrate and stays there. The sheet is gently peeled off, leaving the flake in place. This looks like so:</p>

<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-3-480.webp" />
    <source media="(max-width: 800px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-3-800.webp" />
    <source media="(max-width: 1400px)" srcset="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-3-1400.webp" />
    -->
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/image-3.png" data-zoomable="">
  </picture>
</figure>

<p>You can also read more about this process in <a href="https://arxiv.org/pdf/1311.4829.pdf" target="_blank" rel="noopener noreferrer">this paper</a>. To actually make something useful, you will need to repeat this flake transfer multiple times and build really complex, tiny structures. The unfortunate hard part is that all of this is a really slow, manual process that requires a lot of patience.</p>

<h1 id="the-solution">The solution</h1>

<p>The solution is to automatically track the flakes from the camera feed and use that data to automatically guide a robotic arm to assemble a structure. You could then leave the assembly robot overnight and come back to complete structures.</p>

<p>One (unworkable) approach is to try fine-tuning an AI model, like <a href="https://en.wikipedia.org/wiki/You_Only_Look_Once" target="_blank" rel="noopener noreferrer">YOLO</a>, to detect the flake for you. This didn’t work because we only had 3 really short videos of the above transfer process.</p>

<p>Because we don’t have enough data, we are left in the ‘classical’ mode of computer vision: frame-differencing, edge detection, et al. So, the algorithm we develop looks like this:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">video</span> <span class="o">=</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">video.mp4</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># Extract frame as a `numpy` array from video feed, using `pyav`
</span><span class="n">background</span> <span class="o">=</span> <span class="nf">blur</span><span class="p">(</span><span class="nf">rolling_ball</span><span class="p">(</span><span class="n">video</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">video</span><span class="p">)[::</span><span class="mi">3</span><span class="p">]:</span> <span class="c1"># every 3rd frame only
</span>  <span class="n">frame</span> <span class="o">=</span> <span class="nf">togray</span><span class="p">(</span><span class="nf">down</span><span class="p">(</span><span class="n">frame</span><span class="p">))</span> <span class="o">-</span> <span class="n">background</span> <span class="c1"># Downsample, grayscale and subtract background. 
</span>  <span class="n">edges</span> <span class="o">=</span> <span class="nf">binarydilate</span><span class="p">(</span><span class="nf">canny</span><span class="p">(</span><span class="n">frame</span><span class="p">))</span> <span class="c1"># detect edges and dilate to connect edge breaks. 
</span>  <span class="n">blobs</span> <span class="o">=</span> <span class="nf">fill_holes</span><span class="p">(</span><span class="nf">watershed</span><span class="p">(</span><span class="n">edges</span><span class="p">))</span> <span class="c1"># Fill holes to make blobs
</span>  <span class="n">labels</span> <span class="o">=</span> <span class="nf">labels</span><span class="p">(</span><span class="n">blobs</span><span class="p">)</span> <span class="c1"># Separate blobs get separate IDs
</span></code></pre></div></div>

<p>This is the basic layout of the code. However, as the plastic sheet touches the substrate, the background changes—it becomes lighter. When that happens, we simply invalidate and recalculate the background.</p>

<p>This is the core of the algorithm that allows us to track the nanoflakes with really good precision and virtually no data, as shown below:</p>

<figure>
  <div class="container text-center">
  <video height="" class="" width="70%" autoplay="" loop="" muted="">
    <!-- <img  src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/aa-processed-compressed.webm"    /> -->
    <source src="https://github.com/tornikeo/cdn/raw/master/assets/atomic_arch/aa-processed-compressed.webm" type="video/mp4"></source>

  </video>
</div>
<figcaption class="caption"><p>Result of CV processing the video feed (notice how the color of the crystal’s ID ‘ID09-08’ turns to black when the contact line is fully covering it). Green lines from the crystal denote the closest distance to the contact line (also shown as a green curve)</p>
</figcaption></figure>

<h1 id="conclusion">Conclusion</h1>

<p>Automating the detection and tracking of 2D material flakes using classical computer vision techniques enables efficient robotic assembly, even with minimal annotated data. By using edge detection and image manipulation the system can track the microscopic flakes in this transfer process. This approach reduces manual labor required for constructing complex 2D material structures and could be used for automated fabrication.</p>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        <!-- &copy; Copyright 2025 Tornike  Onoprishvili.  -->Last updated: October 02, 2025.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootstrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>
  <script src="/assets/js/spinner.js"></script>
  <script src="/assets/js/image_comparison.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

